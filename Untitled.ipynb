{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5b8e759a-f9fe-4f26-8e21-10b008eed935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f439615a-4ba1-40a2-927f-3ead12f1eb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>education omba executive leadership university texas 20162018 bachelor science accounting richland college 20052008 training certifications certified management accountant cma certified financial modeling valuation analyst compliance antimoney laundering 092016 american institute banking certified public account cpa lean six sigma green belt certified trade products financial regulations 082016 american institute banking achievements speaker bringing leader within 082019 successfully presented empowering speech leadership 500 participants speaker dallas convention cpas 032019 successfully delivered seminar 3k cpas convention guests teaching experience online teacher udemy 2017 taught online accounting nonaccountant course udemy similar online teaching platforms developed effective teaching modules materials curriculum target students took feedbacks students assist improving teaching methodology materials professional memberships affiliations american society executives 2018 present technical skills quickbooks erp sap oracle hyperion languages english native fellow chartered accountant 2011 present ms office sql ibm cognos german spanish french full professional proficiency limited working proficiency limited working proficiency interests artificial intelligence chess nnovoresumecom sailing cryptocurrencies page 2 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category  \\\n",
       "0  Accountant   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Text  \n",
       "0  education omba executive leadership university texas 20162018 bachelor science accounting richland college 20052008 training certifications certified management accountant cma certified financial modeling valuation analyst compliance antimoney laundering 092016 american institute banking certified public account cpa lean six sigma green belt certified trade products financial regulations 082016 american institute banking achievements speaker bringing leader within 082019 successfully presented empowering speech leadership 500 participants speaker dallas convention cpas 032019 successfully delivered seminar 3k cpas convention guests teaching experience online teacher udemy 2017 taught online accounting nonaccountant course udemy similar online teaching platforms developed effective teaching modules materials curriculum target students took feedbacks students assist improving teaching methodology materials professional memberships affiliations american society executives 2018 present technical skills quickbooks erp sap oracle hyperion languages english native fellow chartered accountant 2011 present ms office sql ibm cognos german spanish french full professional proficiency limited working proficiency limited working proficiency interests artificial intelligence chess nnovoresumecom sailing cryptocurrencies page 2 2  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_atlas = pd.read_csv('./Resumes/resume_atlas/train.csv')\n",
    "resume_atlas.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "24bbf6b7-a741-4327-b75f-871c0ee704b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(resume_atlas['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6269384a-601f-44ae-ab13-75f53b70997f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA &amp; Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \\r\\n\\r\\nData Science Assurance Associate \\r\\n\\r\\nData Science Assurance Associate - Ernst &amp; Young LLP\\r\\nSkill Details \\r\\nJAVASCRIPT- Exprience - 24 months\\r\\njQuery- Exprience - 24 months\\r\\nPython- Exprience - 24 monthsCompany Details \\r\\ncompany - Ernst &amp; Young LLP\\r\\ndescription - Fraud Investigations and Dispute Services   Assurance\\r\\nTECHNOLOGY ASSISTED REVIEW\\r\\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\\r\\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\\r\\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\\r\\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\\r\\n\\r\\nTools &amp; Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\\r\\n\\r\\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\\r\\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative &amp; Neutral) and time series analysis on customer comments across all 4 categories.\\r\\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\\r\\n* Created customized tableau dashboards for effective reporting and visualizations.\\r\\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\\r\\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\\r\\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\\r\\n\\r\\nTools &amp; Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\\r\\n\\r\\nINFORMATION GOVERNANCE\\r\\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\\r\\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\\r\\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\\r\\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\\r\\nTools &amp; Technologies: Python, Flask, Elastic Search, Kibana\\r\\n\\r\\nFRAUD ANALYTIC PLATFORM\\r\\nFraud Analytics and investigative platform to review all red flag cases.\\r\\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\\r\\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\\r\\nTools &amp; Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category  \\\n",
       "0  Data Science   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Resume  \n",
       "0  Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \\r\\n\\r\\nData Science Assurance Associate \\r\\n\\r\\nData Science Assurance Associate - Ernst & Young LLP\\r\\nSkill Details \\r\\nJAVASCRIPT- Exprience - 24 months\\r\\njQuery- Exprience - 24 months\\r\\nPython- Exprience - 24 monthsCompany Details \\r\\ncompany - Ernst & Young LLP\\r\\ndescription - Fraud Investigations and Dispute Services   Assurance\\r\\nTECHNOLOGY ASSISTED REVIEW\\r\\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\\r\\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\\r\\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\\r\\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\\r\\n\\r\\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\\r\\n\\r\\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\\r\\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\\r\\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\\r\\n* Created customized tableau dashboards for effective reporting and visualizations.\\r\\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\\r\\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\\r\\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\\r\\n\\r\\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\\r\\n\\r\\nINFORMATION GOVERNANCE\\r\\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\\r\\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\\r\\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\\r\\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\\r\\nTools & Technologies: Python, Flask, Elastic Search, Kibana\\r\\n\\r\\nFRAUD ANALYTIC PLATFORM\\r\\nFraud Analytics and investigative platform to review all red flag cases.\\r\\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\\r\\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\\r\\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_gaurav = pd.read_csv('./Resumes/UpdatedResumeDataSet.csv')\n",
    "resume_gaurav.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "763de88f-7932-40e5-8d83-3eaf15c660e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = list(resume_gaurav['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e32154b4-ff64-4218-a8f2-8086b63d0c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(set(l1+l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "21f25e78-5983-49b2-a202-c601a4a9583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Flutter Developer</td>\n",
       "      <td>We are looking for hire experts flutter developer. So you are eligible this post then apply your resume.\\nJob Types: Full-time, Part-time\\nSalary: ₹20,000.00 - ₹40,000.00 per month\\nBenefits:\\nFlexible schedule\\nFood allowance\\nSchedule:\\nDay shift\\nSupplemental Pay:\\nJoining bonus\\nOvertime pay\\nExperience:\\ntotal work: 1 year (Preferred)\\nHousing rent subsidy:\\nYes\\nIndustry:\\nSoftware Development\\nWork Remotely:\\nTemporarily due to COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Job Title  \\\n",
       "0           0  Flutter Developer   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                   Job Description  \n",
       "0  We are looking for hire experts flutter developer. So you are eligible this post then apply your resume.\\nJob Types: Full-time, Part-time\\nSalary: ₹20,000.00 - ₹40,000.00 per month\\nBenefits:\\nFlexible schedule\\nFood allowance\\nSchedule:\\nDay shift\\nSupplemental Pay:\\nJoining bonus\\nOvertime pay\\nExperience:\\ntotal work: 1 year (Preferred)\\nHousing rent subsidy:\\nYes\\nIndustry:\\nSoftware Development\\nWork Remotely:\\nTemporarily due to COVID-19  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc = pd.read_csv('job_title_des.csv')\n",
    "job_desc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4331e46e-a8f1-44e2-b5c3-abeadd834ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(job_desc['Job Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bc1cdd8f-2aad-49e8-9144-867b74067ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Id</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>location</th>\n",
       "      <th>Country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Company Size</th>\n",
       "      <th>...</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Role</th>\n",
       "      <th>Job Portal</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Company</th>\n",
       "      <th>Company Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1089843540111562</td>\n",
       "      <td>5 to 15 Years</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>$59K-$99K</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>Isle of Man</td>\n",
       "      <td>54.2361</td>\n",
       "      <td>-4.5481</td>\n",
       "      <td>Intern</td>\n",
       "      <td>26801</td>\n",
       "      <td>...</td>\n",
       "      <td>001-381-930-7517x737</td>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Social Media Manager</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>Social Media Managers oversee an organizations social media presence. They create and schedule content, engage with followers, and analyze social media metrics to drive brand awareness and engagement.</td>\n",
       "      <td>{'Flexible Spending Accounts (FSAs), Relocation Assistance, Legal Assistance, Employee Recognition Programs, Financial Counseling'}</td>\n",
       "      <td>Social media platforms (e.g., Facebook, Twitter, Instagram) Content creation and scheduling Social media analytics and insights Community engagement Paid social advertising</td>\n",
       "      <td>Manage and grow social media accounts, create engaging content, and interact with the online community. Develop social media content calendars and strategies. Monitor social media trends and engagement metrics.</td>\n",
       "      <td>Icahn Enterprises</td>\n",
       "      <td>{\"Sector\":\"Diversified\",\"Industry\":\"Diversified Financials\",\"City\":\"Sunny Isles Beach\",\"State\":\"Florida\",\"Zip\":\"33160\",\"Website\":\"www.ielp.com\",\"Ticker\":\"IEP\",\"CEO\":\"David Willetts\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job Id     Experience Qualifications Salary Range location  \\\n",
       "0  1089843540111562  5 to 15 Years         M.Tech    $59K-$99K  Douglas   \n",
       "\n",
       "       Country  latitude  longitude Work Type  Company Size  ...  \\\n",
       "0  Isle of Man   54.2361    -4.5481    Intern         26801  ...   \n",
       "\n",
       "                Contact                     Job Title                  Role  \\\n",
       "0  001-381-930-7517x737  Digital Marketing Specialist  Social Media Manager   \n",
       "\n",
       "  Job Portal  \\\n",
       "0   Snagajob   \n",
       "\n",
       "                                                                                                                                                                                            Job Description  \\\n",
       "0  Social Media Managers oversee an organizations social media presence. They create and schedule content, engage with followers, and analyze social media metrics to drive brand awareness and engagement.   \n",
       "\n",
       "                                                                                                                              Benefits  \\\n",
       "0  {'Flexible Spending Accounts (FSAs), Relocation Assistance, Legal Assistance, Employee Recognition Programs, Financial Counseling'}   \n",
       "\n",
       "                                                                                                                                                                         skills  \\\n",
       "0  Social media platforms (e.g., Facebook, Twitter, Instagram) Content creation and scheduling Social media analytics and insights Community engagement Paid social advertising   \n",
       "\n",
       "                                                                                                                                                                                                     Responsibilities  \\\n",
       "0  Manage and grow social media accounts, create engaging content, and interact with the online community. Develop social media content calendars and strategies. Monitor social media trends and engagement metrics.   \n",
       "\n",
       "             Company  \\\n",
       "0  Icahn Enterprises   \n",
       "\n",
       "                                                                                                                                                                          Company Profile  \n",
       "0  {\"Sector\":\"Diversified\",\"Industry\":\"Diversified Financials\",\"City\":\"Sunny Isles Beach\",\"State\":\"Florida\",\"Zip\":\"33160\",\"Website\":\"www.ielp.com\",\"Ticker\":\"IEP\",\"CEO\":\"David Willetts\"}  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd = pd.read_csv('job_descriptions.csv')\n",
    "jd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8970a871-18ec-41d4-9345-9947a91c4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = list(jd['Job Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67e47c32-f734-46a7-be76-0541c0f7c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_par = pd.read_parquet('./Job_Descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c46dc8ca-c95f-4e61-972e-827da27ca878",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = list(jd_par['Primary Keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a681a63b-d866-446c-bf48-cc68eb2fe465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(set(l1 + l2 + l3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "281123f5-4373-4ee9-8290-80f80714c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "l1 = ['Blockchain', 'Business Analyst', 'Consultant', 'Data Science', 'Database', 'DevOps', 'DotNet Developer', 'ETL Developer', 'Java Developer', 'Network Security Engineer', 'Python Developer', 'React Developer', 'SAP Developer', 'SQL Developer', 'Testing', 'Web Designing']\n",
    "l2 = ['Data Science', 'Web Designing', 'Java Developer', 'Business Analyst', 'SAP Developer', 'Automation Testing', 'Python Developer', 'DevOps Engineer', 'Network Security Engineer', 'Database', 'Hadoop', 'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing']\n",
    "\n",
    "print(len(set(l1+l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1477086d-bfc3-456e-8ee3-17ae305d6b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "l1 = [ \"Web Developer\", \"Network Engineer\", \"Software Tester\", \"UX/UI Designer\", \"QA Analyst\", \"Network Administrator\", \"Software Engineer\", \"Network Security Specialist\", \"UI Developer\", \"Data Analyst\", \"Technical Writer\", \"Systems Administrator\", \"Database Administrator\", \"Data Engineer\", \"Java Developer\", \"Front-End Engineer\", \"Front-End Developer\", \"Back-End Developer\", \"Systems Analyst\", \"Database Developer\", \"Software Developer\", \"IT Support Specialist\", \"Software Architect\", \"QA Engineer\", \"Data Scientist\", \"IT Manager\", \"IT Administrator\", \"Systems Engineer\", \"Network Technician\", \"UX Researcher\", \"Business Analyst\", \"Product Manager\", ]\n",
    "l2 = ['Flutter Developer', 'Django Developer', 'Machine Learning', 'iOS Developer', 'Full Stack Developer', 'Java Developer', 'JavaScript Developer', 'DevOps Engineer', 'Software Engineer', 'Database Administrator', 'Wordpress Developer', 'PHP Developer', 'Backend Developer', 'Network Administrator', 'Node js developer']\n",
    "l3 = [\"Sysadmin\", \".NET\", \"JavaScript\", \"PHP\", \"Data Science\", \"Python\", \"Java\", \"DevOps\", \"Node.js\", \"C++\", \"SQL\", \"Ruby\", \"Unity\", \"Android\", \"Data Engineer\", \"QA Automation\", \"Scala\", \"iOS\", \"QA\", \"Technical Writing\", \"Security\", \"Scrum Master\", \"Data Analyst\", \"Golang\", \"Flutter\", \"Rust\", \"Salesforce\", \"Block-chain\", \"SAP\", \"React\", \"Business Analyst\", \"Product Manager\", \"Product Owner\", ]\n",
    "\n",
    "print(len(set(l1+l2+l3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ead489a6-f5bf-4020-9890-b83634c0d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2485\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def count_files(directory: str | Path) -> int:\n",
    "    directory = Path(directory).expanduser().resolve()\n",
    "    return sum(1 for p in directory.rglob('*') if p.is_file())\n",
    "\n",
    "target_dir = './resume_pds/data/data'\n",
    "print(count_files(target_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "24f3715d-2ae4-413a-894d-8e4bcc2d639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = pd.read_parquet('./Job_Descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "704f5689-d649-4aeb-89a9-2183944f6ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141897, 10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6cb4dced-5715-44e2-87d0-be361bc2cd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Position', 'Long Description', 'Company Name', 'Exp Years',\n",
       "       'Primary Keyword', 'English Level', 'Published',\n",
       "       'Long Description_lang', 'id', '__index_level_0__'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "872a9709-9e14-486d-8b45-7c7a6373cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c470ff72-e6f4-48bf-95ff-cc96b17df225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jds = pd.read_csv('./gold_samples/job_desc_sampled.csv')\n",
    "df_resumes = pd.read_csv('./gold_samples/resumes_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "428fb585-c373-4cd1-abe5-631b7aeb63b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>category</th>\n",
       "      <th>resume_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>R27</td>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>jessica claire 100 montgomery st 10th floor 555 4321000 resumesampleexamplecom summary 13 years experience strong background sdlc data integration tools including informatica powercenter informatica intelligent cloud services iics informatica powerexchange idq business intelligence tools like power bi expertise data warehousedata mart ods oltp olap implementations teamed project scope analysis requirements gathering data modeling effort estimation etl design development system testing implementation production support experience working informatica iics tool effectively using data integration data migration multiple source systems experience working iics concepts relating data integration monitor administrator deployments permissions schedules expertise informatica power center 102101951901867 1 extracting data oracle sql server teradata db2 databases flat files web services apis xml json files worked various transformations like normalizer expression rank filter group aggregator lookups joiner sequence generator sorter sqlt stored procedure update strategy source qualifier transaction control union etc expertise implementing complex business rules creating complex mappingsmapplets shortcuts reusable transformations partitioning sessions experience performance tuning sources targets mappings transformations sessions experience installation configuration informatica power center 10x9x client server unix experience performance tuning debugging existing etl processes experience integration various data sources like oracle teradata sql server db2 flat files various formats like fixed width csv excel designed complex mappings load snowflake expertise sqlplsql programming developing executing packages stored procedures functions triggers table partitioning materialized views skills informatica intelligent cloud services informatica powercenter 102101969108608518171 informatica powerexchange 101969108608518171 ticbo designer 5 oracle 12c11g10g9i8x sql server 200820052000 ms access teradata40 mysql toad 1212 c c xml msdos windows95982000xpvistawindows 10 unix plsql agile methodology activemq raml json sqlplus sql developer sqlloader sql plsql git hub shell scripting snowflake salesforce automic dimensional data modeling star schema modeling experience sr informaticaiics developer 092021 current cognizant technology solutions bellevue wa jm family enterprises inc specialized vehicle processing distribution retail vehicle sales finance insurance responsibilities understanding business rules sourcing data multiple source systems using iics designing customizing data models data warehouse supporting data multiple sources implemented type1 type2 cdc incremental load strategies extracted data flat files excel files transformed data based user requirement using informatica power center performed analysis quality source data determine accuracy information reported debugging mappings used session log files trace errors occur loading performance tuning optimizing mappings sessions performed unit testing tuned better performance worked closely dbas admins etl developers change control management team migrating developed mappings across dev qa prod environments provide support deployment activities production support activities environment iicsinformatica power center 104iicssnowflakeoracle exadatasql servermongodb sr informatica developeriics developer 102020 082021 brown brown inc columbia sc pra health sciences inc provides comprehensive clinical development services including data management statistical analysis clinical trial management medical writing regulatory drug development consulting responsibilities designed built iics mappings extract data sfdc oracle sql server loaded oracledesigned etl flows generating flat file extracts per business need worked converting informatica powercenter etl code iics using pc cloud conversion service involved enhancements maintenance activities data warehouse implemented type1 type2 incremental load strategies iics handled configuration activities like setup run time environment create connections schedulestasksmappingsmapplets components designed mappings integration templates bundles task flows used various transformations extract data different formatted files relational source system developed tested informatica mappings based specification design develop plsql packages stored procedure tables views indexes functions implement best practices maintain optimal performance developedautomated powercenteriics jobs automic environment iics informatica power center 104102 salesforce oracle sql server github sr informatica developer 042011 102020 tennessee valley authority tva city state tennessee valley authority corporate agency united states provides electricity business customers local power companies serving 10 million people parts seven southeastern states sr software engineer involved implementation enterprise asset management p6 data warehousing cdc efms maximo 75 version upgrade tririga enterprise content management portfolio optimization project power supply enterprise material tracking system supported various software database upgrades responsibilities involved requirement gathering analysis design development project worked design development informatica powercenter mappings workflows load data multiple sources staging area data warehouse data marts sql server oracle real time extensively used informatica power center iics create mappings sessions workflows populating data dimension fact lookup tables simultaneously different source systems sql server oracle flat files used change data capture cdc capture changes multiple environments deliver accurate data business data warehouse applications worked migrating informatica powercenter code iics experience integrating data using iics reporting needs provided leadership direction project team understanding business processes gathering requirements identifying potential usability issues managing scope ensuring appropriate level application quality maintained times providing architecture review proposed projects enhancements aid governance process decision making worked repository db find deviations companys etl standards objects created users sources targets transformations log files mappings sessions workflows integrated data quality routines informatica mappings standardize cleanse data involved performance tuning source target mappings sessions system levels designed developed unix scripts scheduling jobs using pmcmd involved providing technical support team members well business performance tuning using round robin hash auto key key range partitioning successfully implemented slowly changing dimensions successfully integrated multiple xml sources created denormalized flatstructured file involved writing sql stored procedures functions triggers views oracle database ensure support requests properly approved documented communicated using team foundation servertfs worked project managers developers quality assurance customers resolve technical issues estimated work hours tracked progress using agile methodology reviewed etl code worked development teams correct problems run test scenarios prepare deployment met stakeholders contractor product teams customers throughout system development life cycle delivered signoff deliverables pertaining transactional data warehouse tested troubleshooting methods devised innovative solutions documented resolutions inclusion knowledge base support team use environment informatica power center 1021019691861 iics informatica power exchange 1029691861 informatica data quality 861 google bigquery admin console oracle 12c11g10g sql server 2005 plsql unix windowsnt40 tableau power bigit team foundation server tfs etl developer 122010 042011 wells fargo bank city state wells fargo bank one largest commercial banks united states provides customers full range financial products services etl developer wells fargo bank mortgage project design develop implement etl process load products data mart helped generate business intelligence performance management reports responsibilities extensively involved gathering business requirements translating technical requirements used informatica powercenter ab initio extract data mainframe responsible strictly maintaining naming standards warehouse standards future development coordination leading offshore development activities extracted data various sources flat files mainframe sap oracle using informatica power exchange designed developed stored procedures db2 achieved performance improvement tuning sql queries extraction procedures oracledb2 power center offered 247 production support application timetime basis developed complex power center mappings using different transformations components respectively meet data integration data quality requirements created monitored workflowssessions using informatica server managerworkflow monitor load data target oracle database performed unit testing integration testing user acceptance testing proactively identify data discrepancies inaccuracies involved performance tuning source target mapping session level prepared design documents etl specifications migration documents maintained daily tech tracker updates team regarding objects issues progress involved informatica power center 811 repository upgrade informatica power center 861 involved providing informatica technical support team members well business environment ab initio informatica power center 811861 teradata oracle education training master science software engineering 7 2010 stratford university falls church va bachelor technology electronics communication engineering 2 2008 jntu hyderabad ap informatica certified professional cdi cai r38iics informatica power center 8 certified developer certifications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id       category  \\\n",
       "26       R27  ETL Developer   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   resume_text  \n",
       "26  jessica claire 100 montgomery st 10th floor 555 4321000 resumesampleexamplecom summary 13 years experience strong background sdlc data integration tools including informatica powercenter informatica intelligent cloud services iics informatica powerexchange idq business intelligence tools like power bi expertise data warehousedata mart ods oltp olap implementations teamed project scope analysis requirements gathering data modeling effort estimation etl design development system testing implementation production support experience working informatica iics tool effectively using data integration data migration multiple source systems experience working iics concepts relating data integration monitor administrator deployments permissions schedules expertise informatica power center 102101951901867 1 extracting data oracle sql server teradata db2 databases flat files web services apis xml json files worked various transformations like normalizer expression rank filter group aggregator lookups joiner sequence generator sorter sqlt stored procedure update strategy source qualifier transaction control union etc expertise implementing complex business rules creating complex mappingsmapplets shortcuts reusable transformations partitioning sessions experience performance tuning sources targets mappings transformations sessions experience installation configuration informatica power center 10x9x client server unix experience performance tuning debugging existing etl processes experience integration various data sources like oracle teradata sql server db2 flat files various formats like fixed width csv excel designed complex mappings load snowflake expertise sqlplsql programming developing executing packages stored procedures functions triggers table partitioning materialized views skills informatica intelligent cloud services informatica powercenter 102101969108608518171 informatica powerexchange 101969108608518171 ticbo designer 5 oracle 12c11g10g9i8x sql server 200820052000 ms access teradata40 mysql toad 1212 c c xml msdos windows95982000xpvistawindows 10 unix plsql agile methodology activemq raml json sqlplus sql developer sqlloader sql plsql git hub shell scripting snowflake salesforce automic dimensional data modeling star schema modeling experience sr informaticaiics developer 092021 current cognizant technology solutions bellevue wa jm family enterprises inc specialized vehicle processing distribution retail vehicle sales finance insurance responsibilities understanding business rules sourcing data multiple source systems using iics designing customizing data models data warehouse supporting data multiple sources implemented type1 type2 cdc incremental load strategies extracted data flat files excel files transformed data based user requirement using informatica power center performed analysis quality source data determine accuracy information reported debugging mappings used session log files trace errors occur loading performance tuning optimizing mappings sessions performed unit testing tuned better performance worked closely dbas admins etl developers change control management team migrating developed mappings across dev qa prod environments provide support deployment activities production support activities environment iicsinformatica power center 104iicssnowflakeoracle exadatasql servermongodb sr informatica developeriics developer 102020 082021 brown brown inc columbia sc pra health sciences inc provides comprehensive clinical development services including data management statistical analysis clinical trial management medical writing regulatory drug development consulting responsibilities designed built iics mappings extract data sfdc oracle sql server loaded oracledesigned etl flows generating flat file extracts per business need worked converting informatica powercenter etl code iics using pc cloud conversion service involved enhancements maintenance activities data warehouse implemented type1 type2 incremental load strategies iics handled configuration activities like setup run time environment create connections schedulestasksmappingsmapplets components designed mappings integration templates bundles task flows used various transformations extract data different formatted files relational source system developed tested informatica mappings based specification design develop plsql packages stored procedure tables views indexes functions implement best practices maintain optimal performance developedautomated powercenteriics jobs automic environment iics informatica power center 104102 salesforce oracle sql server github sr informatica developer 042011 102020 tennessee valley authority tva city state tennessee valley authority corporate agency united states provides electricity business customers local power companies serving 10 million people parts seven southeastern states sr software engineer involved implementation enterprise asset management p6 data warehousing cdc efms maximo 75 version upgrade tririga enterprise content management portfolio optimization project power supply enterprise material tracking system supported various software database upgrades responsibilities involved requirement gathering analysis design development project worked design development informatica powercenter mappings workflows load data multiple sources staging area data warehouse data marts sql server oracle real time extensively used informatica power center iics create mappings sessions workflows populating data dimension fact lookup tables simultaneously different source systems sql server oracle flat files used change data capture cdc capture changes multiple environments deliver accurate data business data warehouse applications worked migrating informatica powercenter code iics experience integrating data using iics reporting needs provided leadership direction project team understanding business processes gathering requirements identifying potential usability issues managing scope ensuring appropriate level application quality maintained times providing architecture review proposed projects enhancements aid governance process decision making worked repository db find deviations companys etl standards objects created users sources targets transformations log files mappings sessions workflows integrated data quality routines informatica mappings standardize cleanse data involved performance tuning source target mappings sessions system levels designed developed unix scripts scheduling jobs using pmcmd involved providing technical support team members well business performance tuning using round robin hash auto key key range partitioning successfully implemented slowly changing dimensions successfully integrated multiple xml sources created denormalized flatstructured file involved writing sql stored procedures functions triggers views oracle database ensure support requests properly approved documented communicated using team foundation servertfs worked project managers developers quality assurance customers resolve technical issues estimated work hours tracked progress using agile methodology reviewed etl code worked development teams correct problems run test scenarios prepare deployment met stakeholders contractor product teams customers throughout system development life cycle delivered signoff deliverables pertaining transactional data warehouse tested troubleshooting methods devised innovative solutions documented resolutions inclusion knowledge base support team use environment informatica power center 1021019691861 iics informatica power exchange 1029691861 informatica data quality 861 google bigquery admin console oracle 12c11g10g sql server 2005 plsql unix windowsnt40 tableau power bigit team foundation server tfs etl developer 122010 042011 wells fargo bank city state wells fargo bank one largest commercial banks united states provides customers full range financial products services etl developer wells fargo bank mortgage project design develop implement etl process load products data mart helped generate business intelligence performance management reports responsibilities extensively involved gathering business requirements translating technical requirements used informatica powercenter ab initio extract data mainframe responsible strictly maintaining naming standards warehouse standards future development coordination leading offshore development activities extracted data various sources flat files mainframe sap oracle using informatica power exchange designed developed stored procedures db2 achieved performance improvement tuning sql queries extraction procedures oracledb2 power center offered 247 production support application timetime basis developed complex power center mappings using different transformations components respectively meet data integration data quality requirements created monitored workflowssessions using informatica server managerworkflow monitor load data target oracle database performed unit testing integration testing user acceptance testing proactively identify data discrepancies inaccuracies involved performance tuning source target mapping session level prepared design documents etl specifications migration documents maintained daily tech tracker updates team regarding objects issues progress involved informatica power center 811 repository upgrade informatica power center 861 involved providing informatica technical support team members well business environment ab initio informatica power center 811861 teradata oracle education training master science software engineering 7 2010 stratford university falls church va bachelor technology electronics communication engineering 2 2008 jntu hyderabad ap informatica certified professional cdi cai r38iics informatica power center 8 certified developer certifications  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resumes[df_resumes['resume_id'] == 'R27']#['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a6bcde08-9a82-4ebf-84ef-e8ef7a6237b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jd_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JD6</td>\n",
       "      <td>Middle Python Developer for Big Data project 35 + Welcome Bonus 3000 Python</td>\n",
       "      <td>Position: Middle Python Developer for Big Data project 35 + Welcome Bonus 3000 ; Long Description: The Enterprise Analytics team at the customer’s company has an open position for a Python Developer for a Big Data project. The team builds platforms to provide insights to internal and external clients of customer’s businesses in auto property damage and repair, medical claims, and telematics data. The customer’s solutions include analytical applications for claim processing, workflow productivity, financial performance, client and consumer satisfaction, and industry benchmarks. Data engineers use big data technology to create best-in-industry analytics capability. This position is an opportunity to use Hadoop and Spark ecosystem tools and technology for micro-batch and streaming analytics. Data behaviors include ingestion, standardization, metadata management, business rule curation, data enhancement, and statistical computation against data sources that include relational, XML, JSON, streaming, REST API, and unstructured data. The role has responsibility to understand, prepare, process and analyze data to drive operational, analytical and strategic business decisions. The Data Engineer will work closely with product owners, information engineers, data scientists, data modelers, infrastructure support and data governance positions. We look for engineers who start with 2-3 years of experience in the big data arena but who also love to learn new tools and techniques in a big data landscape that is endlessly changing. **About Exadel:** Since 1998 Exadel has been engineering its own software products and custom software for clients of all sizes. Headquartered in Walnut Creek, California, Exadel currently has 1000+ employees in development centers across America, Europe and Asia. **About the Customer:** The customer is an American company based in Chicago. It accelerates digital transformation for the insurance and automotive industries with AI, IoT and workflow solutions. **About the Project:** The customer has been working on an analytics platform since 2018. The platform is on Hadoop and the Hortonworks Data Platform, and the customer is planning on moving it to Amazon EMR in 2021. The customer has a variety of products, the data for all of which comes into one data lake on this analytics platform, which also allows the customer to do next generation analytics on the amassed data. **Architecture:** Hortonworks is the current vendor. It will be replaced by Amazon EMR. Tableau is going to be the BI vendor. Microstrategy currently exists and will be phased out by early 2023. All data is sent to the data lake, and the customer can do industry reporting. These data are used by a data science team to build new products and an AI model. We will be moving to real-time streaming using Kafka and S3. We are doing POC to use Dremio and Presto for the query engine. We're migrating to version 2.0 using Amazon EMR and S3, and Query engine is bucketed under 2.0 project. **Project Advantages:** Cross product analytics Analytics for every new product customer has. Analytics team products is how the customer sells the products value to clients Quarterly Business Review meetings use data to explain how customer’s product is helping clients in their business You'll get to work with a cross-functional team You will learn the customer’s company business **Project Tech Stack:** Technologies used are all open source Hadoop, Hive, PySpark, Airflow, Kafka to name a few **Project Stage:** Active Development **Must Have Qualifications:** Proficiency in Python 1.5+ years experience building, maintaining, and supporting complex data flows with structural and unstructural data Experience working with distributed applications Ability to use SQL for data profiling and data validation Master’s or Bachelor’s degree **Nice to have:** PySpark Hands-on experience working with HDFS / or HIVE / or SQOOP Understanding of AWS ecosystem and services such as EMR and S3 Familiarity with Apache Kafka and Apache Airflow Experience in Unix commands and scripting Experience and understanding of Continuous Integration and Continuous Delivery (CI/CD) Understanding in performance tuning in distributed computing environment (such as Hadoop cluster or EMR) **Responsibilities:** Build end-to-end data flows from sources to fully curated and enhanced data sets. This can include the effort to locate and analyze source data, create data flows to extract, profile, and store ingested data, define and build data cleansing and imputation, map to a common data model, transform to satisfy business rules and statistical computations, and validate data content Modify, maintain, and support existing data pipelines to provide business continuity and fulfill product enhancement requests Provide technical expertise to diagnose errors from production support teams **Company offers:** Vacation is 20 working days / till 20 working days per year for sick leaves Full payment of taxes English courses Flexible work schedule Friendly environment Medical insurance Opportunity for career growth ; Company Name: Exadel ; Exp Years: 2y ; Primary Keyword: Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  jd_id  \\\n",
       "5   JD6   \n",
       "\n",
       "                                                                     job_title  \\\n",
       "5  Middle Python Developer for Big Data project 35 + Welcome Bonus 3000 Python   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       job_description  \n",
       "5  Position: Middle Python Developer for Big Data project 35 + Welcome Bonus 3000 ; Long Description: The Enterprise Analytics team at the customer’s company has an open position for a Python Developer for a Big Data project. The team builds platforms to provide insights to internal and external clients of customer’s businesses in auto property damage and repair, medical claims, and telematics data. The customer’s solutions include analytical applications for claim processing, workflow productivity, financial performance, client and consumer satisfaction, and industry benchmarks. Data engineers use big data technology to create best-in-industry analytics capability. This position is an opportunity to use Hadoop and Spark ecosystem tools and technology for micro-batch and streaming analytics. Data behaviors include ingestion, standardization, metadata management, business rule curation, data enhancement, and statistical computation against data sources that include relational, XML, JSON, streaming, REST API, and unstructured data. The role has responsibility to understand, prepare, process and analyze data to drive operational, analytical and strategic business decisions. The Data Engineer will work closely with product owners, information engineers, data scientists, data modelers, infrastructure support and data governance positions. We look for engineers who start with 2-3 years of experience in the big data arena but who also love to learn new tools and techniques in a big data landscape that is endlessly changing. **About Exadel:** Since 1998 Exadel has been engineering its own software products and custom software for clients of all sizes. Headquartered in Walnut Creek, California, Exadel currently has 1000+ employees in development centers across America, Europe and Asia. **About the Customer:** The customer is an American company based in Chicago. It accelerates digital transformation for the insurance and automotive industries with AI, IoT and workflow solutions. **About the Project:** The customer has been working on an analytics platform since 2018. The platform is on Hadoop and the Hortonworks Data Platform, and the customer is planning on moving it to Amazon EMR in 2021. The customer has a variety of products, the data for all of which comes into one data lake on this analytics platform, which also allows the customer to do next generation analytics on the amassed data. **Architecture:** Hortonworks is the current vendor. It will be replaced by Amazon EMR. Tableau is going to be the BI vendor. Microstrategy currently exists and will be phased out by early 2023. All data is sent to the data lake, and the customer can do industry reporting. These data are used by a data science team to build new products and an AI model. We will be moving to real-time streaming using Kafka and S3. We are doing POC to use Dremio and Presto for the query engine. We're migrating to version 2.0 using Amazon EMR and S3, and Query engine is bucketed under 2.0 project. **Project Advantages:** Cross product analytics Analytics for every new product customer has. Analytics team products is how the customer sells the products value to clients Quarterly Business Review meetings use data to explain how customer’s product is helping clients in their business You'll get to work with a cross-functional team You will learn the customer’s company business **Project Tech Stack:** Technologies used are all open source Hadoop, Hive, PySpark, Airflow, Kafka to name a few **Project Stage:** Active Development **Must Have Qualifications:** Proficiency in Python 1.5+ years experience building, maintaining, and supporting complex data flows with structural and unstructural data Experience working with distributed applications Ability to use SQL for data profiling and data validation Master’s or Bachelor’s degree **Nice to have:** PySpark Hands-on experience working with HDFS / or HIVE / or SQOOP Understanding of AWS ecosystem and services such as EMR and S3 Familiarity with Apache Kafka and Apache Airflow Experience in Unix commands and scripting Experience and understanding of Continuous Integration and Continuous Delivery (CI/CD) Understanding in performance tuning in distributed computing environment (such as Hadoop cluster or EMR) **Responsibilities:** Build end-to-end data flows from sources to fully curated and enhanced data sets. This can include the effort to locate and analyze source data, create data flows to extract, profile, and store ingested data, define and build data cleansing and imputation, map to a common data model, transform to satisfy business rules and statistical computations, and validate data content Modify, maintain, and support existing data pipelines to provide business continuity and fulfill product enhancement requests Provide technical expertise to diagnose errors from production support teams **Company offers:** Vacation is 20 working days / till 20 working days per year for sick leaves Full payment of taxes English courses Flexible work schedule Friendly environment Medical insurance Opportunity for career growth ; Company Name: Exadel ; Exp Years: 2y ; Primary Keyword: Python  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jds[df_jds['jd_id'] == 'JD6']#['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42ee5222-ce68-4d28-a238-bc22cc27687e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                    Java Developer\n",
       "1                                                                                             Senior Java Developer (Kita One) Java\n",
       "2                                                                                                Junior/Regular Java Developer Java\n",
       "3                                                                                                               Java Developer Java\n",
       "4                                                                                                                    Java Developer\n",
       "5                                                       Middle Python Developer for Big Data project 35 + Welcome Bonus 3000 Python\n",
       "6                                                                                Software Engineer (Python / ReactJS) QA Automation\n",
       "7                                                                            Senior Data Engineer with Python and AWS Data Engineer\n",
       "8                                                                                               Python Django Lead\\Architect Python\n",
       "9                                                                     Frontend Developer (JavaScript, Python) Blockchain JavaScript\n",
       "10                                                                                                                   Data Scientist\n",
       "11                                                                            Python Software Engineer/ Data Scientist Data Science\n",
       "12                                                                                                                   Data Scientist\n",
       "13                                                                                                                   Data Scientist\n",
       "14                                                                                                                   Data Scientist\n",
       "15                                                                                                                 Business Analyst\n",
       "16                                                                                  Senior Business System Analyst Business Analyst\n",
       "17                                                                                    Business Development Manager Business Analyst\n",
       "18                                                                                                Business Analyst Business Analyst\n",
       "19                                                                                                                 Business Analyst\n",
       "20                                                                             DevOps Engineer for a cyber-security platform DevOps\n",
       "21                                                                        Senior DevOps Engineer (with Manager competencies) DevOps\n",
       "22                                                                                                    Senior DevOps engineer DevOps\n",
       "23                                                                                                    Middle DevOps Engineer DevOps\n",
       "24                                                                                                           DevOps Engineer DevOps\n",
       "25                                                                                                                    Data Engineer\n",
       "26                                                                          Senior Data Engineer (Data Platform Team) Data Engineer\n",
       "27                                                                                                      Data Engineer Data Engineer\n",
       "28                                                                                                                    Data Engineer\n",
       "29                                                                                                                    Data Engineer\n",
       "30                                                                                     Junior/Middle Manual QA Engineer (Mobile) QA\n",
       "31                                                                             Senior QA Engineer and/or QA Team Lead QA Automation\n",
       "32                                                                                                                   QA engineer QA\n",
       "33    Middle Manual QA Engineer for a software product helping airports, hotels and restaurants to meet HACCP cleaning standards QA\n",
       "34                                                                                                                      QA Engineer\n",
       "35                                                                                               Middle .NET Backend Developer .NET\n",
       "36                                                                           Strong Middle Full Stack (.NET+Angular) developer .NET\n",
       "37                                                          Senior Full-Stack Engineer (AI and Cognitive Services Engineering) .NET\n",
       "38                                                                                                               .Net Engineer .NET\n",
       "39                                                                                            Full Stack Developer (.NET + JS) .NET\n",
       "40                                                                                                      Network Security Specialist\n",
       "41                                                                                                      Network Security Specialist\n",
       "42                                                                                                      Network Security Specialist\n",
       "43                                                                                                      Network Security Specialist\n",
       "44                                                                                                      Network Security Specialist\n",
       "45                                                                                                                    Web Developer\n",
       "46                                                                                        Middle to Senior Web Developer JavaScript\n",
       "47                                                                                                                    Web Developer\n",
       "48                                                                                                                    Web Developer\n",
       "49                                                                                                                    Web Developer\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jds['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1644863-e819-4e0c-a611-ac13e6dab5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = str(df_jds[df_jds['jd_id'] == 'JD38'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a952508a-05f3-4c89-a01e-a55a7ec94fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chiragjain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text: str) -> set[str]:\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return {tok for tok in tokens if tok not in STOP_WORDS and not tok.isdigit()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e23f8d8c-d8e3-497c-925f-f8ac9f958284",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1dc76db9-bfeb-41a9-a235-b0d2ab92cd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a695b-b0dd-4605-94ff-e6302267c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
