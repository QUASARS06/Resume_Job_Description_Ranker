{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1810a2-f4a1-4708-9e95-8a28372ff49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding with sentence-transformers/all-MiniLM-L6-v2 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████| 2/2 [00:00<00:00,  3.00it/s]\n",
      "Batches: 100%|████████████████████████████████████| 2/2 [00:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re‑ranking with cross-encoder/ms-marco-MiniLM-L6-v2 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:21<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Retrieval quality (average over 50 resumes)  ===\n",
      "         Metric  Value\n",
      "   Precision@10 0.3300\n",
      "      Recall@10 0.3300\n",
      "Top‑10 accuracy 0.9400\n",
      "         MRR@10 0.6264\n",
      "        NDCG@10 0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re, ast, torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "res_df = pd.read_csv('./gold_samples/resumes_samples.csv')\n",
    "jd_df  = pd.read_csv('./gold_samples/job_desc_sampled.csv')\n",
    "\n",
    "res_texts = res_df['resume_text'].tolist()\n",
    "jd_texts  = jd_df['job_description'].tolist()\n",
    "\n",
    "gold_file = Path(\"gold_res.txt\")\n",
    "row_pat   = re.compile(r\"R(\\d+)\\s*:\\s*\\[(.*)\\]\")\n",
    "jd_pat    = re.compile(r\"JD\\d+\")\n",
    "\n",
    "gold_dict = {}\n",
    "with gold_file.open() as fh:\n",
    "    for raw in fh:\n",
    "        m = row_pat.match(raw.strip())\n",
    "        if not m:\n",
    "            continue\n",
    "        rid      = f\"R{m.group(1)}\"\n",
    "        jd_list  = jd_pat.findall(m.group(2))\n",
    "        gold_dict[rid] = jd_list\n",
    "\n",
    "\n",
    "bi_name  = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bi_model = SentenceTransformer(bi_name)\n",
    "\n",
    "print(f\"Encoding with {bi_name} …\")\n",
    "res_emb = bi_model.encode(res_texts, batch_size=32,\n",
    "                          normalize_embeddings=True, show_progress_bar=True)\n",
    "jd_emb  = bi_model.encode(jd_texts,  batch_size=32,\n",
    "                          normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "initial_hits = util.semantic_search(res_emb, jd_emb, top_k=50)  # list of lists\n",
    "\n",
    "ce_name  = \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n",
    "cross    = CrossEncoder(ce_name)\n",
    "print(f\"Re‑ranking with {ce_name} …\")\n",
    "\n",
    "retrieved = {}           \n",
    "\n",
    "for ridx, hits in enumerate(tqdm(initial_hits)):\n",
    "    cand_ids = [h['corpus_id'] for h in hits]\n",
    "    pairs    = [(res_texts[ridx], jd_texts[j]) for j in cand_ids]\n",
    "    scores   = cross.predict(pairs, batch_size=16)\n",
    "    reranked = [cand_ids[i] for i in np.argsort(scores)[::-1]]   # best→worst\n",
    "\n",
    "    top_jds  = jd_df.iloc[reranked[:10]]['jd_id'].tolist()\n",
    "    retrieved[f\"R{ridx+1}\"] = top_jds\n",
    "\n",
    "\n",
    "def precision_at_k(pred, gold, k=10):\n",
    "    return len(set(pred[:k]) & set(gold)) / k\n",
    "\n",
    "def recall_at_k(pred, gold, k=10):\n",
    "    return len(set(pred[:k]) & set(gold)) / len(gold)\n",
    "\n",
    "def mrr_at_k(pred, gold, k=10):\n",
    "    for rank, jd in enumerate(pred[:k], 1):\n",
    "        if jd in gold:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(pred, gold, k=10):\n",
    "    dcg = sum(1/np.log2(rank+1) for rank, jd in enumerate(pred[:k],1) if jd in gold)\n",
    "    idcg = sum(1/np.log2(r+1) for r in range(1, min(len(gold),k)+1))\n",
    "    return dcg/idcg if idcg else 0.0\n",
    "\n",
    "def topk_accuracy(pred, gold, k=10):\n",
    "    return int(bool(set(pred[:k]) & set(gold)))\n",
    "\n",
    "P,R,ACC,MRR,NDCG = [],[],[],[],[]\n",
    "for rid, pred_jds in retrieved.items():\n",
    "    gold_jds = gold_dict[rid]\n",
    "    P.append(precision_at_k(pred_jds, gold_jds))\n",
    "    R.append(recall_at_k(pred_jds, gold_jds))\n",
    "    ACC.append(topk_accuracy(pred_jds, gold_jds))\n",
    "    MRR.append(mrr_at_k(pred_jds, gold_jds))\n",
    "    NDCG.append(ndcg_at_k(pred_jds, gold_jds))\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "        \"Metric\": [\"Precision@10\",\"Recall@10\",\"Top‑10 accuracy\",\"MRR@10\",\"NDCG@10\"],\n",
    "        \"Value\":  [np.mean(P), np.mean(R), np.mean(ACC), np.mean(MRR), np.mean(NDCG)]})\n",
    "\n",
    "print(\"\\n===  Retrieval quality (average over 50 resumes)  ===\")\n",
    "print(metrics.to_string(index=False, float_format=lambda x: f\"{x:0.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd7912-f07a-4051-b38b-d4ac3157548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rid in sorted(retrieved.keys(), key=lambda s: int(s[1:])):\n",
    "    print(f\"{rid} → {retrieved[rid]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
