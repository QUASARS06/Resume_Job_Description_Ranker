{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c198f048-f865-4270-b435-018217c6c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, random, math, numpy as np, pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from rank_bm25 import BM25Okapi   # BM25 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "debc66da-56a2-4783-bb4b-5443e50de6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_PARQUET       = \"resumes.parquet\"\n",
    "JD_PARQUET           = \"job_description.parquet\"\n",
    "GOLD_RESUMES_CSV     = \"./gold_samples/resumes_samples.csv\"\n",
    "GOLD_JDS_CSV         = \"./gold_samples/job_desc_sampled.csv\"\n",
    "GOLD_TOP10_PATH      = \"gold_res.txt\"\n",
    "\n",
    "K = 10                            # evaluate @ top‑K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e51b780-4c19-4ddb-8122-0eb2c10077ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet …\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading parquet …\")\n",
    "df_resumes = pd.read_parquet(RESUME_PARQUET)          # ≈ 4 k rows\n",
    "df_jds     = pd.read_parquet(JD_PARQUET)              # ≈ 492 k rows\n",
    "\n",
    "gold_resumes_df = pd.read_csv(GOLD_RESUMES_CSV)       # 50 rows\n",
    "gold_jds_df     = pd.read_csv(GOLD_JDS_CSV)           # 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d51a5ae-90e8-4cea-bf0e-1f31170d4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_STOP = {\n",
    "    \"experience\",\"experiences\",\"years\",\"year\",\"requirements\",\"requirement\",\n",
    "    \"responsibilities\",\"responsibility\",\"ability\",\"excellent\",\"strong\",\n",
    "    \"demonstrated\",\"proven\",\"successful\",\"successfully\",\"including\",\"etc\",\n",
    "    \"must\",\"will\",\"role\",\"position\",\"candidate\",\"applicant\",\"opportunity\",\n",
    "    \"team\",\"teams\",\"work\",\"working\",\"environment\",\"environments\",\"dynamic\",\n",
    "    \"fast‑paced\",\"communication\",\"communications\",\"written\",\"verbal\",\n",
    "    \"skills\",\"skill\",\"interpersonal\",\"detail\",\"details\",\"organization\",\n",
    "    \"organizational\",\"problem\",\"problems\",\"solve\",\"solving\",\"solutions\",\n",
    "    \"solution\",\"manage\",\"management\",\"managed\",\"managing\",\"lead\",\"leading\",\n",
    "    \"leadership\",\"support\",\"supporting\",\"supported\",\"ensure\",\"ensuring\",\n",
    "    \"responsible\",\"provide\",\"providing\",\"provided\",\"perform\",\"performing\",\n",
    "    \"performed\",\"deliver\",\"delivering\",\"delivered\",\"design\",\"designing\",\n",
    "    \"designed\",\"develop\",\"developing\",\"developed\",\"development\",\"process\",\n",
    "    \"processes\",\"project\",\"projects\",\"business\",\"client\",\"clients\",\"customer\",\n",
    "    \"customers\",\"stakeholder\",\"stakeholders\",\"company\",\"companies\",\"function\",\n",
    "    \"functions\",\"functional\",\"collaborate\",\"collaborating\",\"collaboration\",\n",
    "    \"across\",\"within\",\"preferred\",\"plus\",\"bonus\",\"equivalent\",\"related\",\n",
    "    \"knowledge\",\"familiar\",\"familiarity\",\"understanding\",\"concepts\"\n",
    "}\n",
    "\n",
    "ALIAS_MAP = {\n",
    "    \"k8s\":\"kubernetes\",\"gke\":\"kubernetes\",\"eks\":\"kubernetes\",\"aks\":\"kubernetes\",\n",
    "    \"gcp\":\"google‑cloud\",\"aws\":\"amazon‑web‑services\",\"azure\":\"microsoft‑azure\",\n",
    "    \"js\":\"javascript\",\"nodejs\":\"node‑js\",\"node.js\":\"node‑js\",\n",
    "    \".net\":\"dotnet\",\"asp.net\":\"aspnet\",\"c#\":\"csharp\",\"c++\":\"cpp\",\n",
    "    \"py\":\"python\",\"ts\":\"typescript\",\"tf\":\"tensorflow\",\"tfserving\":\"tensorflow‑serving\",\n",
    "    \"np\":\"numpy\",\"ml\":\"machine‑learning\",\"dl\":\"deep‑learning\",\"pytorch\":\"torch\",\n",
    "    \"gql\":\"graphql\",\"sqlserver\":\"sql‑server\",\"tsql\":\"t‑sql\",\"postgres\":\"postgresql\",\n",
    "    \"psql\":\"postgresql\",\"mongo\":\"mongodb\",\"ci/cd\":\"continuous‑integration‑continuous‑delivery\",\n",
    "    \"ci\":\"continuous‑integration\",\"cd\":\"continuous‑delivery\",\"infra\":\"infrastructure\",\n",
    "    \"svc\":\"service\",\"svc‑mesh\":\"service‑mesh\",\"msgq\":\"message‑queue\",\n",
    "    \"msg‑q\":\"message‑queue\",\"gh\":\"github\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b046de1-d6ed-4cb6-bff5-ecfd069235b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up spaCy …\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up spaCy …\")\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"parser\"])\n",
    "BASE_STOP = set(nlp.Defaults.stop_words)\n",
    "punct_tbl = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "def tok_normalize(text:str)->list[str]:\n",
    "    text = text.translate(punct_tbl).lower()\n",
    "    for k,v in ALIAS_MAP.items():\n",
    "        text = text.replace(k, v)\n",
    "    doc = nlp(text)\n",
    "    return [tok.lemma_ for tok in doc\n",
    "            if tok.is_alpha and len(tok)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df78aa52-4ae0-4ddd-a7b1-e28e3f637a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_stop(tokens_lists, df_thresh=0.75, sample_size=50_000):\n",
    "    sample = random.sample(tokens_lists, min(sample_size,len(tokens_lists)))\n",
    "    df_counter = Counter()\n",
    "    for toks in sample:\n",
    "        df_counter.update(set(toks))\n",
    "    cut = math.ceil(df_thresh * len(sample))\n",
    "    return {t for t,df in df_counter.items() if df>=cut}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "198e83df-e6f9-44b9-97d3-c822d67fb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached token lists …\n"
     ]
    }
   ],
   "source": [
    "import joblib, os, pickle\n",
    "\n",
    "CACHE_DIR = Path(\"./cache_bm25\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "JDTOK_PATH   = CACHE_DIR / \"jd_tokens.pkl\"\n",
    "RESTOK_PATH  = CACHE_DIR / \"resume_tokens_full.pkl\"\n",
    "STOP_PATH    = CACHE_DIR / \"auto_stop.pkl\"\n",
    "\n",
    "def dump(obj, path):\n",
    "    with path.open(\"wb\") as fh:\n",
    "        pickle.dump(obj, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(path):\n",
    "    with path.open(\"rb\") as fh:\n",
    "        return pickle.load(fh)\n",
    "\n",
    "if JDTOK_PATH.exists() and RESTOK_PATH.exists() and STOP_PATH.exists():\n",
    "    print(\"Loading cached token lists …\")\n",
    "    jd_tokens           = load(JDTOK_PATH)\n",
    "    resume_tokens_full  = load(RESTOK_PATH)\n",
    "    AUTO_STOP           = load(STOP_PATH)\n",
    "else:\n",
    "    print(\"Tokenizing JD corpus …\")\n",
    "    jd_tokens = [tok_normalize(t) for t in tqdm(df_jds.job_description)]\n",
    "\n",
    "    print(\"Tokenizing resume corpus …\")\n",
    "    resume_tokens_full = [tok_normalize(t) for t in tqdm(df_resumes.resume_text)]\n",
    "\n",
    "    print(\"Deriving auto stop‑words …\")\n",
    "    AUTO_STOP = learn_stop(jd_tokens + resume_tokens_full, 0.75)\n",
    "\n",
    "    dump(jd_tokens,          JDTOK_PATH)\n",
    "    dump(resume_tokens_full, RESTOK_PATH)\n",
    "    dump(AUTO_STOP,          STOP_PATH)\n",
    "    print(f\"Saved token lists & auto‑stop list → {CACHE_DIR}\")\n",
    "\n",
    "STOPWORDS = BASE_STOP | EXTRA_STOP | AUTO_STOP\n",
    "def drop_stop(tok_list): return [t for t in tok_list if t not in STOPWORDS]\n",
    "\n",
    "jd_tokens          = [drop_stop(t) for t in jd_tokens]\n",
    "resume_tokens_full = [drop_stop(t) for t in resume_tokens_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e78082f0-48fb-4443-8220-a0b7adc0b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop‑word tally → default:326 +extra:109 +auto:0 = 431\n"
     ]
    }
   ],
   "source": [
    "AUTO_STOP = learn_stop(jd_tokens + resume_tokens_full, 0.75)\n",
    "STOPWORDS = BASE_STOP | EXTRA_STOP | AUTO_STOP\n",
    "\n",
    "def drop_stop(toks): return [t for t in toks if t not in STOPWORDS]\n",
    "\n",
    "jd_tokens = [drop_stop(t) for t in jd_tokens]\n",
    "resume_tokens_full = [drop_stop(t) for t in resume_tokens_full]\n",
    "\n",
    "print(f\"Stop‑word tally → default:{len(BASE_STOP)} \"\n",
    "      f\"+extra:{len(EXTRA_STOP)} +auto:{len(AUTO_STOP)} = {len(STOPWORDS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a834c55a-814a-4faa-9c9f-90bbeaf7e3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting BM25 …\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'JD1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m jd_id_to_idx = {jd_id: i \u001b[38;5;28;01mfor\u001b[39;00m i,jd_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df_jds.jd_id, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_jds)))}\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# indices of the 50 gold JDs in the big corpus\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m gold_jd_indices = [\u001b[43mjd_id_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjid\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m jid \u001b[38;5;129;01min\u001b[39;00m gold_jds_df.jd_id]\n\u001b[32m     12\u001b[39m gold_jd_ids_arr = gold_jds_df.jd_id.to_numpy()\n",
      "\u001b[31mKeyError\u001b[39m: 'JD1'"
     ]
    }
   ],
   "source": [
    "print(\"Fitting BM25 …\")\n",
    "bm25 = BM25Okapi(jd_tokens)\n",
    "\n",
    "jd_id_to_idx = {jd_id: i for i,jd_id in zip(df_jds.jd_id, range(len(df_jds)))}\n",
    "\n",
    "gold_jd_indices = [jd_id_to_idx[jid] for jid in gold_jds_df.jd_id]\n",
    "gold_jd_ids_arr = gold_jds_df.jd_id.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec7cdd-e0ee-4b5a-a1cd-a79227a3c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing gold résumés …\")\n",
    "gold_resume_tokens = [drop_stop(tok_normalize(t))\n",
    "                      for t in tqdm(gold_resumes_df.resume_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17491ede-3aef-49ef-8cd7-ebeb1290b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scoring BM25 …\")\n",
    "pred = {}               # resume_id  →  [top‑K jd_ids]\n",
    "\n",
    "for rid, r_toks in zip(gold_resumes_df.resume_id, gold_resume_tokens):\n",
    "    if not r_toks:\n",
    "        pred[rid] = []\n",
    "        continue\n",
    "    \n",
    "    scores = bm25.get_scores(r_toks)\n",
    "    \n",
    "    sub_scores = scores[gold_jd_indices]   \n",
    "    top_idx_sub = np.argpartition(-sub_scores, K-1)[:K]\n",
    "    \n",
    "    top_idx_sub = top_idx_sub[np.argsort(sub_scores[top_idx_sub])[::-1]]\n",
    "    pred[rid] = gold_jd_ids_arr[top_idx_sub].tolist()\n",
    "\n",
    "pred_df = pd.DataFrame({\"resume_id\":list(pred.keys()),\n",
    "                        \"top10_jds\":list(pred.values())})\n",
    "print(\"\\nPredictions sample:\\n\")\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71760e-91d4-4c6f-bd16-1da1e23b9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_map={}\n",
    "with open(GOLD_TOP10_PATH) as fh:\n",
    "    for line in fh:\n",
    "        if not line.strip(): continue\n",
    "        rid, rest = line.split(\":\",1)\n",
    "        gold_map[rid.strip()] = re.findall(r'JD\\d+', rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce9d2c-8e97-4cc2-be9d-d576678f41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(rel): return sum(r/np.log2(i+2) for i,r in enumerate(rel))\n",
    "\n",
    "prec, rec, acc, rr, ndcg = [], [], [], [], []\n",
    "for rid, gold_jds in gold_map.items():\n",
    "    if rid not in pred: continue\n",
    "    hits = [int(j in gold_jds) for j in pred[rid]]\n",
    "    prec.append(np.mean(hits))\n",
    "    rec.append(sum(hits)/len(gold_jds))\n",
    "    acc.append(int(any(hits)))\n",
    "    rr.append(next((1/(i+1) for i,h in enumerate(hits) if h), 0))\n",
    "    ideal = min(len(gold_jds), K)\n",
    "    ndcg.append(dcg(hits)/dcg([1]*ideal) if ideal else 0)\n",
    "\n",
    "print(\"\\n──────── Accuracy on gold 50×50 ────────\")\n",
    "print(f\"Precision@{K}:   {np.mean(prec):.4f}\")\n",
    "print(f\"Recall@{K}:      {np.mean(rec):.4f}\")\n",
    "print(f\"Top‑{K} accuracy: {np.mean(acc):.4f}\")\n",
    "print(f\"MRR@{K}:          {np.mean(rr):.4f}\")\n",
    "print(f\"NDCG@{K}:         {np.mean(ndcg):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7c3f3-5bc7-4b72-a17b-1b1561f95c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
